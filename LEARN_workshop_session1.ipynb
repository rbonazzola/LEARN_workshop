{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8819185f",
   "metadata": {},
   "source": [
    "# LEARN Workshop - session 1\n",
    "_17 March 2023_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d2964",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Get on board of the DGX A100 machine and explore its features.\n",
    "- Learn how to build a Docker image with necessary environment to perform DL.\n",
    "- Brainstorm requirements for the LEARN DL/ML platform (with the help of Jack O'Halloran)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b83f9",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d6020",
   "metadata": {},
   "source": [
    "- How to access the DGX machine and launch a Docker container.\n",
    "- Overview of the hardware features.\n",
    "- How to build a Docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aba7f1",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba740b70",
   "metadata": {},
   "source": [
    "**Hardware**\n",
    "- [DGX A100 white paper](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/dgx-a100/dgxa100-system-architecture-white-paper.pdf)\n",
    "- [Nvidia A100 Tensor Core GPU paper](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf)\n",
    "\n",
    "**Multiple Instance GPU (MIG)**\n",
    "- [MIG user guide from Nvidia](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/)\n",
    "\n",
    "**Docker**\n",
    "- [Docker basics - how to use Dockerfiles](https://thenewstack.io/docker-basics-how-to-use-dockerfiles/)\n",
    "\n",
    "**Deep learning training**\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#3-automatic-mixed-precision-training\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#5-training-on-4-gpus-with-distributed-data-parallel\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#6-deepspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826b440",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b198d",
   "metadata": {},
   "source": [
    "## DGX hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6161b",
   "metadata": {},
   "source": [
    "- **GPU**: 40GB per GPU/320 GB per DGX A100 Node\n",
    "- **CPU**: 2-socket, 128 core AMD Rome 7742, 2.25 GHz (base), 3.4GHz (Max boost)\n",
    "- **System Memory**: 1 TB 3200 MHz DDR4.\n",
    "- **Storage:** Data cache drives: 15TB (4x3.84TB gen4 NVME)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda468c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e26925e9",
   "metadata": {},
   "source": [
    "## Multiple Instance GPU (MIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907c3ac",
   "metadata": {},
   "source": [
    "Examine the output of `nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e56c59",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m torch.utils.collect_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686586fa",
   "metadata": {},
   "source": [
    "#### Set up GPU device in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(\"Torch CUDA available?\", torch.cuda.is_available())\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908b4a1",
   "metadata": {},
   "source": [
    "**How to launch a container that \"sees\" specific MIG devices?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3ea43",
   "metadata": {},
   "source": [
    "```bash\n",
    "SOURCEPATH=\"${HOME}/code\"\n",
    "TARGETPATH=\"/app/code\"\n",
    "DOCKER_IMAGE=\"rbonazzola/coma:latest\"\n",
    "DEVICES=\"0:3,0:4,0:5,0:6,1:0,1:1\"\n",
    "\n",
    "docker run -it --rm \\ \n",
    "--shm-size=32gb \\\n",
    "--gpus '\"device='${DEVICES}''\"' \\\n",
    "--mount type=bind,source=${SOURCEPATH},target=${TARGETPATH} \\\n",
    "$DOCKER_IMAGE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ef3e0",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fc38b",
   "metadata": {},
   "source": [
    "### Half-precision floating point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d66db1",
   "metadata": {},
   "source": [
    "- Uses 16-bit representations for floating point number. Default is usually 32 bits.\n",
    "- Saves memory.\n",
    "- Speeds up computation.\n",
    "- Feature also available in Nvidia V100 GPUs (ARC4, Bede, JADE2)\n",
    "- _Not_ available on P100 or K80 GPUs (ARC3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d09e2",
   "metadata": {},
   "source": [
    "#### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b161642",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "A32 = torch.Tensor(N, N).cuda()\n",
    "B32 = torch.Tensor(N, N).cuda()\n",
    "A16 = torch.Tensor(N, N).cuda().type(torch.float16)\n",
    "B16 = torch.Tensor(N, N).cuda().type(torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360cd6c",
   "metadata": {},
   "source": [
    "Let's perform element-wise matrix multiplication to compare the execution times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c26bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A16 * B16\n",
    "%timeit A32 * B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b708f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A16 * B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f49632",
   "metadata": {},
   "outputs": [],
   "source": [
    "A16 = torch.Tensor(N, N).cuda().type(torch.bfloat16)\n",
    "B16 = torch.Tensor(N, N).cuda().type(torch.bfloat16)\n",
    "\n",
    "%timeit A16 * B16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824a555",
   "metadata": {},
   "source": [
    "### Mixed-precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de1300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "172680e8",
   "metadata": {},
   "source": [
    "### MNIST digit recognition (plain PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "mnist_valset, mnist_testset = torch.utils.data.random_split(mnist_testset, [int(0.9 * len(mnist_testset)), int(0.1 * len(mnist_testset))])\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(Subset(mnist_trainset, range(5000)), batch_size=128, shuffle=True)\n",
    "# val_dataloader = torch.utils.data.DataLoader(Subset(mnist_valset, range(1000)), batch_size=32, shuffle=False)\n",
    "# test_dataloader = torch.utils.data.DataLoader(Subset(mnist_testset, range(500)), batch_size=32, shuffle=False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=128, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_valset, batch_size=32, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader.dataset.dataset.data = train_dataloader.dataset.dataset.data.to(device)\n",
    "# val_dataloader.dataset.dataset.dataset.data = val_dataloader.dataset.dataset.dataset.data.to(device)\n",
    "# test_dataloader.dataset.dataset.dataset.data = test_dataloader.dataset.dataset.dataset.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier().cuda()\n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs = 1000\n",
    "train_loss = list()\n",
    "val_loss = list()\n",
    "best_val_loss = 1\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # training\n",
    "    for itr, (image, label) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = ce_loss(pred, label)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_train_loss = total_train_loss / (itr + 1)\n",
    "    train_loss.append(total_train_loss)\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    for itr, (image, label) in enumerate(val_dataloader):\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = ce_loss(pred, label)\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "        for i, p in enumerate(pred):\n",
    "            if label[i] == torch.max(p.data, 0)[1]:\n",
    "                total = total + 1\n",
    "\n",
    "    accuracy = total / len(mnist_valset)\n",
    "\n",
    "    total_val_loss = total_val_loss / (itr + 1)\n",
    "    val_loss.append(total_val_loss)\n",
    "\n",
    "    hora = time.strftime(\"%H:%M:%S\") \n",
    "    print('\\n{} - Epoch: {}/{}, Train Loss: {:.8f}, Val Loss: {:.8f}, Val Accuracy: {:.8f}'.format(hora, epoch + 1, no_epochs, total_train_loss, total_val_loss, accuracy))\n",
    "\n",
    "    if total_val_loss < best_val_loss:\n",
    "        best_val_loss = total_val_loss\n",
    "        print(\"Saving the model state dictionary for Epoch: {} with Validation loss: {:.8f}\".format(epoch + 1, total_val_loss))\n",
    "        torch.save(modelo.state_dict(), \"checkpoints/model.dth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a98b06",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a32069",
   "metadata": {},
   "source": [
    "### PyTorch Lightning (PTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbea83",
   "metadata": {},
   "source": [
    "- Library built on top of PyTorch.\n",
    "- Gets rid of boilerplate code.\n",
    "- **Allows to access hardware capabilities more easily.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as ptl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff611b28",
   "metadata": {},
   "source": [
    "It's built around three key abstractions:\n",
    "- `ptl.Module`: model itself plus specifications on what to do at each stage (training/validation/testing/inference)\n",
    "- `ptl.DataModule`: data + how to partition the data\n",
    "- `ptl.Trainer`: object that is fed with the two previous and performs the training. Hardware details must be specified through this object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e620c9",
   "metadata": {},
   "source": [
    "Let's use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b8dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9de75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d518bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MNIST_module\n",
    "# import MNIST_datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "from pytorch_lightning.callbacks import RichModelSummary\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss', save_top_k=1)\n",
    "\n",
    "# rich_model_summary = RichModelSummary(max_depth=-1)\n",
    "\n",
    "progress_bar = RichProgressBar(\n",
    "  theme=RichProgressBarTheme(\n",
    "    description=\"green_yellow\",\n",
    "    progress_bar=\"green1\",\n",
    "    progress_bar_finished=\"green1\",\n",
    "    progress_bar_pulse=\"#6206E0\",\n",
    "    batch_progress=\"green_yellow\",\n",
    "    time=\"grey82\",\n",
    "    processing_speed=\"grey82\",\n",
    "    metrics=\"grey82\",\n",
    "  )\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "    # rich_model_summary\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84db2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ptl.Trainer(\n",
    "  gpus=1,\n",
    "  precision=\"bf16\",\n",
    "  callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0378bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(ptl_module, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6e477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "520e50d8",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a9d56a",
   "metadata": {},
   "source": [
    "# Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e720fbc",
   "metadata": {},
   "source": [
    "### Building your own Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7362658",
   "metadata": {},
   "source": [
    "**_Note:_** ARC3, ARC4, Bede and JADE have Singularity installed, however a Docker image can be run from Singularity. Therefore, if you choose carefully the libraries's versions on your Docker images (such that they are compatible with the Nvidia drivers installed), in principle you could readily use this image on those platforms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
