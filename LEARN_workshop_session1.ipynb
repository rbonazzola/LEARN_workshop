{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8819185f",
   "metadata": {},
   "source": [
    "# LEARN Workshop - session 1\n",
    "_17 March 2023_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d2964",
   "metadata": {},
   "source": [
    "## Objectives of today's session\n",
    "- Get on board of the DGX A100 machine and explore its features.\n",
    "- Learn how to build a Docker image with necessary environment to perform DL.\n",
    "- Brainstorm requirements for the LEARN DL/ML platform (with the help of Jack O'Halloran)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aba7f1",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba740b70",
   "metadata": {},
   "source": [
    "**Hardware**\n",
    "- [DGX A100 white paper](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/dgx-a100/dgxa100-system-architecture-white-paper.pdf)\n",
    "- [Nvidia A100 Tensor Core GPU paper](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf)\n",
    "\n",
    "**Multiple Instance GPU (MIG)**\n",
    "- [MIG user guide from Nvidia](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/)\n",
    "\n",
    "**Docker**\n",
    "- [Docker basics - how to use Dockerfiles](https://thenewstack.io/docker-basics-how-to-use-dockerfiles/)\n",
    "\n",
    "**Deep learning training**\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#3-automatic-mixed-precision-training\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#5-training-on-4-gpus-with-distributed-data-parallel\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#6-deepspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826b440",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450358a",
   "metadata": {},
   "source": [
    "## To get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd949ce",
   "metadata": {},
   "source": [
    "To start off, we will log into the DGX A100, launch a container and open this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcee3e",
   "metadata": {},
   "source": [
    "1. Log into the DGX A100 through SSH (server name: `cistib-dgx01.leeds.ac.uk`). Use your university credentials.\n",
    "2. Check that Docker works on the DGX for your user: run `docker ps` and `docker run hello-world`.\n",
    "3. Clone this repository: \n",
    "  ```bash\n",
    "  git clone https://github.com/rbonazzola/LEARN_workshop.git\n",
    "  ```\n",
    "4. Pull the test Docker image we will use, with the following command: \n",
    "  ```bash\n",
    "  docker pull rbonazzola/learn_workshop:latest\n",
    "  ```\n",
    "5. Launch a container by running these commands:\n",
    "```bash\n",
    "DEVICE=\"1:0\" # change by another device\n",
    "SOURCEPATH=\"${HOME}/LEARN_workshop\" # if you didn't clone the repo in the home dir, change accordingly\n",
    "TARGETPATH=\"/home/user/LEARN_workshop\" # don't replace \"user\"!\n",
    "PORT=13467 # change by another random port >10000\n",
    "docker run -it -p ${PORT}:8888 --shm-size=32gb --gpus '\"device='$DEVICE'\"' --mount type=bind,source=${SOURCEPATH},target=${TARGETPATH} rbonazzola/learn_workshop:latest\n",
    "```\n",
    "6. If the above worked, you should be inside the container. Launch Jupyter Lab or Jupyter Notebook from inside:\n",
    "```bash\n",
    "jupyter lab --ip \"0.0.0.0\" \n",
    "```\n",
    "\n",
    "7. Create an SSH tunnel (using MobaXterm on Windows, or the `ssh` option `\"-L ${PORT}:localhost:${PORT}\"` on Linux).\n",
    "8. Open your local web browser and insert `localhost:PORT` in the address bar, and copy the access token.\n",
    "9. Open this notebook, `LEARN_workshop/LEARN_workshop_session1.ipynb`. **Tip**: create a copy of this notebook (\"save as...\") if you plan to make changes to it. That will prevent future merge issues if you need to do pulls in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8d602",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b198d",
   "metadata": {},
   "source": [
    "## DGX hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6161b",
   "metadata": {},
   "source": [
    "- **GPU**: 40GB per GPU/320 GB per DGX A100 Node\n",
    "- **CPU**: 2-socket, 128 core AMD Rome 7742, 2.25 GHz (base), 3.4GHz (Max boost)\n",
    "- **System Memory**: 1 TB 3200 MHz DDR4.\n",
    "- **Storage:** \n",
    "    - **Default**: 15TB (4x3.84TB gen4 NVME).\n",
    "    - **Purchased with this machine**: 105 TB drive [PNY 3S-1050](https://www.scan.co.uk/3xs/configurator/3s-1050) AI-optimised storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216dae20",
   "metadata": {},
   "source": [
    "![](figures/DGX_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26925e9",
   "metadata": {},
   "source": [
    "## Multiple Instance GPU (MIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69417d94",
   "metadata": {},
   "source": [
    "(_from [Nvidia MIG user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/)_) \n",
    "\n",
    "The new Multi-Instance GPU (MIG) feature allows GPUs (starting with NVIDIA Ampere architecture) to be securely partitioned into up to seven separate GPU Instances for CUDA applications, providing multiple users with separate GPU resources for optimal GPU utilization. This feature is particularly beneficial for workloads that do not fully saturate the GPU's compute capacity and therefore users may want to run different workloads in parallel to maximize utilization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c42044",
   "metadata": {},
   "source": [
    "![](figures/DGX_MIG_partitioning_schemes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907c3ac",
   "metadata": {},
   "source": [
    "Currently, all the GPUs are partitioned into seven 5GB chunks (MIG devices), except GPU 6 which is partitioned into two 20GB MIG devices. Partitioning requires `sudo` so the admins (Ale and Kattia) have to be contacted in order to change this configuration.\n",
    "\n",
    "Examine the output of `nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222db56b",
   "metadata": {},
   "source": [
    "## Using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120fbac",
   "metadata": {},
   "source": [
    "Let's examine the environment. Run this from the command line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e56c59",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m torch.utils.collect_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686586fa",
   "metadata": {},
   "source": [
    "#### Set up GPU device in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(\"Torch CUDA available?\", torch.cuda.is_available())\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ef3e0",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fc38b",
   "metadata": {},
   "source": [
    "### Half-precision floating point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d66db1",
   "metadata": {},
   "source": [
    "- Uses 16-bit representations for floating point number. Default is usually 32 bits.\n",
    "- Saves memory.\n",
    "- Speeds up computation.\n",
    "- Feature also available in Nvidia V100 GPUs (ARC4, Bede, JADE2)\n",
    "- _Not_ available on P100 or K80 GPUs (ARC3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a591e",
   "metadata": {},
   "source": [
    "![](figures/DGX_16_bit_precision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f5d05",
   "metadata": {},
   "source": [
    "![](.figures/DGX_16_bit_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d09e2",
   "metadata": {},
   "source": [
    "#### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b161642",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "A32 = torch.Tensor(N, N).cuda()\n",
    "B32 = torch.Tensor(N, N).cuda()\n",
    "A16 = torch.Tensor(N, N).cuda().type(torch.float16)\n",
    "B16 = torch.Tensor(N, N).cuda().type(torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360cd6c",
   "metadata": {},
   "source": [
    "Let's perform element-wise matrix multiplication ($\\mathcal{O}(n^2)$) to compare the execution times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c26bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A16 * B16\n",
    "%timeit A32 * B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b708f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A16 * B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f49632",
   "metadata": {},
   "outputs": [],
   "source": [
    "A16 = torch.Tensor(N, N).cuda().type(torch.bfloat16)\n",
    "B16 = torch.Tensor(N, N).cuda().type(torch.bfloat16)\n",
    "\n",
    "%timeit A16 * B16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8b920",
   "metadata": {},
   "source": [
    "Now, some standard matrix products ($\\mathcal{O}(n^3)$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da41051",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit torch.mm(A16, B16)\n",
    "%timeit torch.mm(A32, B32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172680e8",
   "metadata": {},
   "source": [
    "### MNIST digit recognition (plain PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ab70d",
   "metadata": {},
   "source": [
    "Let's train a simple CNN MNIST classifier using plain PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "mnist_trainset, mnist_valset = torch.utils.data.random_split(mnist_trainset, [int(0.8 * len(mnist_trainset)), int(0.2 * len(mnist_trainset))])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=256, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_valset, batch_size=32, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier().cuda()\n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "train_loss = list()\n",
    "val_loss = list()\n",
    "best_val_loss = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # training\n",
    "    for itr, (image, label) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = ce_loss(pred, label)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_train_loss = total_train_loss / (itr + 1)\n",
    "    train_loss.append(total_train_loss)\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    for itr, (image, label) in enumerate(val_dataloader):\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = ce_loss(pred, label)\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "        for i, p in enumerate(pred):\n",
    "            if label[i] == torch.max(p.data, 0)[1]:\n",
    "                total = total + 1\n",
    "\n",
    "    accuracy = total / len(mnist_valset)\n",
    "\n",
    "    total_val_loss = total_val_loss / (itr + 1)\n",
    "    val_loss.append(total_val_loss)\n",
    "\n",
    "    timestamp = time.strftime(\"%H:%M:%S\") \n",
    "    print('\\n{} - Epoch: {}/{}, Train Loss: {:.8f}, Val Loss: {:.8f}, Val Accuracy: {:.8f}'.format(timestamp, epoch + 1, N_EPOCHS, total_train_loss, total_val_loss, accuracy))\n",
    "\n",
    "    if total_val_loss < best_val_loss:\n",
    "        best_val_loss = total_val_loss\n",
    "        print(\"Saving the model state dictionary for Epoch: {} with Validation loss: {:.8f}\".format(epoch + 1, total_val_loss))\n",
    "        torch.save(model.state_dict(), \"checkpoints/model.dth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a98b06",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a32069",
   "metadata": {},
   "source": [
    "### PyTorch Lightning (PTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbea83",
   "metadata": {},
   "source": [
    "- Library built on top of PyTorch.\n",
    "- Gets rid of boilerplate code.\n",
    "- **Allows to access hardware capabilities more easily.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as ptl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff611b28",
   "metadata": {},
   "source": [
    "It's built around three key abstractions:\n",
    "- `ptl.Module`: model itself plus specifications on what to do at each stage (training/validation/testing/inference)\n",
    "- `ptl.DataModule`: data + how to partition the data\n",
    "- `ptl.Trainer`: object that is fed with the two previous and performs the training. Hardware details must be specified through this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "from pytorch_lightning.callbacks import RichModelSummary\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss', save_top_k=1)\n",
    "\n",
    "rich_model_summary = RichModelSummary(max_depth=-1)\n",
    "\n",
    "progress_bar = RichProgressBar(\n",
    "  theme=RichProgressBarTheme(\n",
    "    description=\"green_yellow\",\n",
    "    progress_bar=\"green1\",\n",
    "    progress_bar_finished=\"green1\",\n",
    "    progress_bar_pulse=\"#6206E0\",\n",
    "    batch_progress=\"green_yellow\",\n",
    "    time=\"grey82\",\n",
    "    processing_speed=\"grey82\",\n",
    "    metrics=\"grey82\",\n",
    "  )\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "    rich_model_summary\n",
    "]\n",
    "\n",
    "trainer = ptl.Trainer(\n",
    "  gpus=1,\n",
    "  precision=16,\n",
    "  callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257449d7",
   "metadata": {},
   "source": [
    "Let's import the ptl.Module and ptl.DataModule from the file `MNIST_lightning.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53946d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNIST_lightning import CNN_Module, MNIST_DataModule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac74d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "PRECISION = 16 # try 32, 64, \"bf16\"\n",
    "\n",
    "datamodule = MNIST_DataModule(batch_size=BATCH_SIZE, split_lengths=[48000, 12000])\n",
    "ptl_module = CNN_Module(model=MNISTClassifier())\n",
    "\n",
    "trainer = ptl.Trainer(\n",
    "  gpus=1,\n",
    "  precision=PRECISION,\n",
    "  callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0378bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(ptl_module, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e50d8",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a9d56a",
   "metadata": {},
   "source": [
    "# Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf2af5",
   "metadata": {},
   "source": [
    "Docker is a software platform that simplifies the process of building, running, managing and distributing applications. It packages applications as images that contain everything needed to run them: code, runtime environment, libraries, and configuration. Images run in containers, which are discrete processes that take up only as many resources as any other executable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e720fbc",
   "metadata": {},
   "source": [
    "### Building your own Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d02eb",
   "metadata": {},
   "source": [
    "There are two ways of doing this:\n",
    "\n",
    "    1. Create a Dockerfile.\n",
    "    2. Modify an existing image interactively and committing the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272b52b",
   "metadata": {},
   "source": [
    "### Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff86b97",
   "metadata": {},
   "source": [
    "Once you have a Dockerfile ready, you can build an image from it running the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031a6fe",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker build -f <DOCKERFILE_LOCATION> -t <IMAGE_NAME> .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc258637",
   "metadata": {},
   "source": [
    "Now we will see how to create a Dockerfile. You can use the one located in this repository under `docker/Dockerfile` as a reference for your own project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53585e4b",
   "metadata": {},
   "source": [
    "**Choose your base image**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70506f41",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM <BASE_IMAGE>\n",
    "```\n",
    "\n",
    "e.g.\n",
    "```Dockerfile\n",
    "FROM ubuntu:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7454b5",
   "metadata": {},
   "source": [
    "**Install libraries (assuming Ubuntu)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d00905",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "RUN apt-get update \n",
    "RUN apt-get install -y \\\n",
    "    curl \\\n",
    "    ca-certificates \\\n",
    "    vim \\\n",
    "    sudo \\\n",
    "    git \\\n",
    "    bzip2 \\\n",
    "    libx11-6 \\\n",
    "    wget \\\n",
    "    zip tar unzip \\\n",
    "    gcc \\\n",
    "    tmux \\\n",
    "    make \\\n",
    " && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get install -y --reinstall build-essential\n",
    "RUN apt-get install -y libboost-dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe388cd7",
   "metadata": {},
   "source": [
    "**Set up your user**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40102fa",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "# Create a non-root user and switch to it.\n",
    "RUN adduser --disabled-password --gecos '' --shell /bin/bash user\n",
    "RUN echo \"user ALL=(ALL) NOPASSWD:ALL\" > /etc/sudoers.d/90-user\n",
    "USER user\n",
    "\n",
    "# All users can use /home/user as their home directory.\n",
    "ENV HOME=/home/user\n",
    "RUN chmod 777 /home/user\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10e26c",
   "metadata": {},
   "source": [
    "**Set up a Conda environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f9c6d",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "RUN curl -so ~/miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n",
    " && chmod +x ~/miniconda.sh \\\n",
    " && ~/miniconda.sh -b -p ~/miniconda \\\n",
    " && rm ~/miniconda.sh\n",
    "ENV PATH=/home/user/miniconda/bin:$PATH\n",
    "ENV CONDA_AUTO_UPDATE_CONDA=false\n",
    "\n",
    "# Create e.g. a Python 3.9 environment.\n",
    "RUN /home/user/miniconda/bin/conda install conda-build\n",
    "RUN /home/user/miniconda/bin/conda create -y --name <ENV_NAME> python=3.9\n",
    "RUN /home/user/miniconda/bin/conda clean -ya\n",
    "\n",
    "ENV CONDA_DEFAULT_ENV=<ENV_NAME>\n",
    "ENV CONDA_PREFIX=/home/user/miniconda/envs/$CONDA_DEFAULT_ENV\n",
    "ENV PATH=$CONDA_PREFIX/bin:$PATH\n",
    "\n",
    "ENV TORCH=1.10\n",
    "ENV CUDA=cu113\n",
    "RUN conda install pytorch=${TORCH} torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "RUN conda install tqdm -c conda-forge\n",
    "RUN conda install jupyter -c anaconda\n",
    "RUN conda install pytorch-lightning -c conda-forge\n",
    "RUN conda install mlflow==1.23 -c conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ffc97",
   "metadata": {},
   "source": [
    "**_Note:_** ARC3, ARC4, Bede and JADE have Singularity installed, however a Docker image can be run from Singularity. Therefore, if you choose carefully the libraries's versions on your Docker images (such that they are compatible with the Nvidia drivers installed), in principle you could readily use this image on those platforms.\n",
    "\n",
    "```bash\n",
    "singularity build <SINGULARITY_IMAGE_NAME>.sif docker-daemon://<DOCKER_IMAGE_NAME>:<TAG>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
