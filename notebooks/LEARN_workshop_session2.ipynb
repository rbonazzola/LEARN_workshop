{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8819185f",
   "metadata": {},
   "source": [
    "# LEARN Workshop - session 2\n",
    "_24 March 2023_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a0675",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9747f3d",
   "metadata": {},
   "source": [
    "## Overview of last session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a7221-b92e-4f99-bbf3-17d8f6bd15eb",
   "metadata": {},
   "source": [
    "- Overview of DGX hardware.\n",
    "- Overview of features.\n",
    "- Justify usage of PyTorch Lightning\n",
    "- Docker: how to build an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9e373-f812-4221-831b-c435be424b39",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d2964",
   "metadata": {},
   "source": [
    "## Objectives of today's session\n",
    "- Explore MLflow and PyTorch Lightning.\n",
    "- Start implementing individual use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aba7f1",
   "metadata": {},
   "source": [
    "## References\n",
    "- [PyTorch Lightning 1.9 docs](https://lightning.ai/docs/pytorch/1.9.3/)\n",
    "- [MLflow docs](https://mlflow.org/docs/latest/index.html)\n",
    "- [Ray Tune docs](https://docs.ray.io/en/latest/tune/index.html), if you want to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc39b6b-1df2-4c01-88f7-051bb24c5bfb",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86223079-97c7-4b9b-9add-1baac134e5cf",
   "metadata": {},
   "source": [
    "- For this session, you need to `docker pull` the image `rbonazzola/learn_workshop:session_2`. \n",
    "- Also, run `git pull` from within the LEARN repo's folder to update the repository with today's contents. If you made changes to the notebook (which you want to preserve), save a copy of it (\"save as...\". Then, run `git reset --hard` to revert the changes on the original file. Finally, run `git pull`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826b440",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b60266",
   "metadata": {},
   "source": [
    "**Note on version compatibility.**\n",
    "\n",
    "From the MLflow docs (2023/03/23) we have:\n",
    "\n",
    "![](figures/mlflow_ptl_compatibility.png)\n",
    "\n",
    "On the other hand, the following chart gives the range of PyTorch versions that officially work with specific Pytorch Lightning versions.\n",
    "\n",
    "![](figures/ptl_compatibility_chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425b99d-ecab-4988-8ae2-e10f464c9dce",
   "metadata": {},
   "source": [
    "For this session, we will use the last version of PTL that is officially supported by MLflow (1.9.3), and the last PyTorch version that is officially supported by the latter (1.13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f4534-c8dd-4d23-bba4-8c418fdf2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as ptl\n",
    "import mlflow\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch Lightning version: {ptl.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a32069",
   "metadata": {},
   "source": [
    "### PyTorch Lightning (PTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbea83",
   "metadata": {},
   "source": [
    "- A lightweight wrapper for PyTorch code.\n",
    "- Requires a precise organisation of the code.\n",
    "- Gets rid of boilerplate code.\n",
    "- **Allows to access hardware capabilities more easily.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff611b28",
   "metadata": {},
   "source": [
    "It's built around three key abstractions:\n",
    "- `ptl.LightningModule`: DL model itself plus specifications on what to do at each stage (training/validation/testing/inference). The optimizer configuration (Adam, SGD, etc.) must be supplied here as well.\n",
    "- `ptl.LightninDataModule`: data + how to partition the data for each stage.\n",
    "- `ptl.Trainer`: object that is fed with the two previous and performs the training. Hardware details must be specified through this object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e565f6-1e75-4995-bccf-c9b682b5a801",
   "metadata": {},
   "source": [
    "The `ptl.LightningModule`:\n",
    "    \n",
    "```\n",
    "class MyPTLModule(ptl.LightningModule):\n",
    "\n",
    "  def __init__(self, ...):\n",
    "      \n",
    "      super().__init__()\n",
    "      ...\n",
    "      \n",
    "      self.training_step_outputs = []\n",
    "      self.validation_step_outputs = []\n",
    "      self.test_step_outputs = []\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "      y = ...\n",
    "      return y\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "      \n",
    "      x, y = batch\n",
    "      y_pred = self(x)\n",
    "      loss = ...\n",
    "      loss_dict = { \"loss\": loss }\n",
    "\n",
    "      self.training_step_outputs.append(loss_dict)\n",
    "        \n",
    "      self.log_dict(loss_dict)      \n",
    "      return loss_dict\n",
    "      \n",
    "  \n",
    "  def on_train_epoch_end(self):\n",
    "        \n",
    "      outputs = self.training_step_outputs\n",
    "\n",
    "      loss = torch.stack([x[\"loss\"] for x in outputs])\n",
    "      \n",
    "      # Do something, e.g.\n",
    "      avg_loss = loss.mean() \n",
    "      \n",
    "      self.log_dict({\n",
    "          \"training_loss\": avg_loss\n",
    "        },\n",
    "        on_epoch=True,\n",
    "        prog_bar=True,\n",
    "        logger=True,\n",
    "      )\n",
    "      self.training_step_outputs.clear()    \n",
    "  \n",
    "\n",
    "  # Same for validation and test\n",
    "  #\n",
    "  # def {validation|test}_step(self, batch, batch_idx):\n",
    "  #     ...\n",
    "  #     ...\n",
    "  #\n",
    "  # def on_{validation|test}_epoch_end(self)\n",
    "  #\n",
    "  # \n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "      optimizer = ...\n",
    "      return optimizer            \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257449d7",
   "metadata": {},
   "source": [
    "Let's import the ptl.Module and ptl.DataModule from the file `MNIST_lightning.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461142cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNIST_example.MNIST import MNISTClassifier\n",
    "from MNIST_lightning import CNN_Module, MNIST_DataModule \n",
    "from my_ptl_callbacks import early_stopping, model_checkpoint, progress_bar, rich_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0db41e-575e-4990-87a4-f50ca6eea0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium') # To enable optimal use of the Tensor Cores of the A100 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac74d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "PRECISION = \"16\" # 64 # try 32, 64, \"bf16\"\n",
    "\n",
    "datamodule = MNIST_DataModule(batch_size=BATCH_SIZE, split_lengths=[48000, 12000])\n",
    "ptl_module = CNN_Module(model=MNISTClassifier())\n",
    "\n",
    "callbacks = [ early_stopping, model_checkpoint, progress_bar, rich_model_summary ]\n",
    "\n",
    "trainer = ptl.Trainer(\n",
    "    accelerator='gpu', devices=1,\n",
    "    precision=PRECISION,\n",
    "    callbacks=callbacks,\n",
    "    min_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0378bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(ptl_module, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3028907-fbc2-4968-8424-ddd3eea071de",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a7a1b",
   "metadata": {},
   "source": [
    "## MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c43702-08d6-4dbb-a835-3f36d2726b47",
   "metadata": {},
   "source": [
    "MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry.\n",
    "\n",
    "MLflow currently offers **four components**:\n",
    "\n",
    "- **MLflow Tracking**. Record and query experiments: code, data, config, and results.\n",
    "- **MLflow Projects**. Package data science code in a format to reproduce runs on any platform.\n",
    "- **MLflow Models**. Deploy machine learning models in diverse serving environments.\n",
    "- **Model Registry**. Store, annotate, discover, and manage models in a central repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edec57b-37ae-47a7-a3df-0d40d1961d84",
   "metadata": {},
   "source": [
    "_We will focus on **MLflow Tracking**._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1b769-775d-4f1e-9697-c9d26fc074a0",
   "metadata": {},
   "source": [
    "### Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7bd877-12e1-405c-a6ce-ee591a775ac4",
   "metadata": {},
   "source": [
    "- **Run**: an instance of model training. More concretely is a collection of parameters (hyperparameters, network weights, seed, reference to input data), metrics, tags and artifacts.\n",
    "- **Experiment**: a set of runs. Primary unit of organization of MLflow.\n",
    "- **Parameters**: key-value parameters, where the value is either numeric or a string.\n",
    "- **Metrics**: key-value metrics, where the value is numeric. Each metric can be updated throughout the course of the run (for example, to track how your model’s loss function is converging), and MLflow records and lets you visualize the metric’s full history (*from [the docs](https://www.MLflow.org/docs/latest/tracking.html#concepts)*).\n",
    "- **Artifacts**: Output files in any format. For example, you can record images (like PNGs), trained models, and data files (for example, a csv file) as artifacts (*from [the docs](https://www.MLflow.org/docs/latest/tracking.html#concepts)*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cdc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "print(f\"{mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f1d7f-e21d-4e71-ad61-0257e41c4613",
   "metadata": {},
   "source": [
    "### Create experiments and runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32cca0-a4a7-4b04-93e4-ece51d83600c",
   "metadata": {},
   "source": [
    "We will create an experiment called `\"TEST\"` and, within it, a run called `test_run` with one \"hyperparameter\" `a=1` and one \"metric\" `b=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed10c93-7980-4daa-a77d-50ec931b43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"./mlruns\" # the location where to store the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ebff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri)\n",
    "exp_name = \"TEST\"\n",
    "\n",
    "try:\n",
    "  exp_id = mlflow.create_experiment(exp_name)\n",
    "except:\n",
    "  # If the experiment already exists, we can just retrieve its ID\n",
    "  exp_id = mlflow.get_experiment_by_name(exp_name).experiment_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cb47e-73d2-41ac-99b5-fd330046d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment name:\", exp_name)\n",
    "print(\"Experiment ID:\", exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6b1d2-c620-4e21-843f-a079588063a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"test_run\"\n",
    "with mlflow.start_run(run_name=run_name, experiment_id=exp_id):    \n",
    "    mlflow.log_param(\"a\", 1)\n",
    "    mlflow.log_metric(\"b\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0463c56-9caf-4f62-8909-0e810226c240",
   "metadata": {},
   "source": [
    "The GUI can be used to explore the experiments and runs using the web browser. To launch it, execute `mlflow ui` on the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc0991-4108-404c-be72-c144e6f261e6",
   "metadata": {},
   "source": [
    "### Explore experiments with the MLflow Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e7210-1e77-4a71-8acd-b791e33573a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e96717-9438-490c-a1e9-d023a6bc67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list = {experiment.name: experiment.experiment_id for experiment in mlflow.search_experiments()}\n",
    "exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f25ef2-21ff-43d6-9202-36996d768fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_w = widgets.SelectMultiple(options=exp_list)\n",
    "exp_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d426de-1de3-4a1c-a24e-eda4c79b319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_w.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246b55b-abf9-46eb-813f-4995033fab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = mlflow.search_runs(\n",
    "    experiment_ids=exp_w.value    \n",
    ")\n",
    "\n",
    "runs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9c655-5bd9-4b56-a2c1-e9945ac89431",
   "metadata": {},
   "source": [
    "## PyTorch Lightning with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ace88-de39-4f90-9f81-18930a7b6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.pytorch.autolog(log_models=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478517b-6e54-466c-96f1-7cad5b097ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "PRECISION = \"16\"\n",
    "\n",
    "model = MNISTClassifier()\n",
    "datamodule = MNIST_DataModule(batch_size=BATCH_SIZE, split_lengths=[48000, 12000])\n",
    "ptl_module = CNN_Module(model)\n",
    "\n",
    "trainer = ptl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    precision=PRECISION,\n",
    "    callbacks=callbacks,\n",
    "    min_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316b793-e0b9-4740-8558-4d9abac4c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(ptl_module, datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
