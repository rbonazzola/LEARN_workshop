{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8819185f",
   "metadata": {},
   "source": [
    "# LEARN Workshop - session 1\n",
    "_17 March 2023_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d2964",
   "metadata": {},
   "source": [
    "## Objectives of today's session\n",
    "- Get on board of the DGX A100 machine and explore its features.\n",
    "- Learn how to build a Docker image with necessary environment to perform DL.\n",
    "- Brainstorm requirements for the LEARN DL/ML platform (with the help of Jack O'Halloran)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aba7f1",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba740b70",
   "metadata": {},
   "source": [
    "**Hardware**\n",
    "- [DGX A100 white paper](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/dgx-a100/dgxa100-system-architecture-white-paper.pdf)\n",
    "- [Nvidia A100 Tensor Core GPU paper](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf)\n",
    "\n",
    "**Multiple Instance GPU (MIG)**\n",
    "- [MIG user guide from Nvidia](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/)\n",
    "\n",
    "**Docker**\n",
    "- [Docker basics - how to use Dockerfiles](https://thenewstack.io/docker-basics-how-to-use-dockerfiles/)\n",
    "\n",
    "**Deep learning training**\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#3-automatic-mixed-precision-training\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#5-training-on-4-gpus-with-distributed-data-parallel\n",
    "- https://sebastianraschka.com/blog/2023/pytorch-faster.html#6-deepspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826b440",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450358a",
   "metadata": {},
   "source": [
    "## To get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd949ce",
   "metadata": {},
   "source": [
    "To start off, we will log into the DGX A100, launch a container and open this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcee3e",
   "metadata": {},
   "source": [
    "1. Log into the DGX A100 through SSH (server name: `cistib-dgx01.leeds.ac.uk`). Use your university credentials.\n",
    "2. Check that Docker works on the DGX for your user: run `docker ps` and `docker run hello-world`.\n",
    "3. Clone this repository: \n",
    "  ```bash\n",
    "  git clone https://github.com/rbonazzola/LEARN_workshop.git\n",
    "  ```\n",
    "4. Pull the test Docker image we will use, with the following command: \n",
    "  ```bash\n",
    "  docker pull rbonazzola/learn_workshop:session_2\n",
    "  ```  \n",
    "  Alternatively, you can build the image yourself (this will take longer). The source `Dockerfile` is called `docker/Dockerfile_pt113_cu117_ptl19`. The command would be (if run from the `LEARN_workshop/docker` directory): `docker build -f Dockerfile_pt113_cu117_ptl19 -t rbonazzola/learn_workshop:session_2 .` (don't forget the dot in the end).\n",
    "  \n",
    "  \n",
    "5. Launch a container by running these commands:\n",
    "```bash\n",
    "DEVICE=\"1:0\" # change by another device. This stands for GPU_ID:MIG_ID.\n",
    "SOURCEPATH=\"${HOME}/LEARN_workshop\" # if you didn't clone the repo in the home dir, change accordingly\n",
    "TARGETPATH=\"/root/LEARN_workshop\"\n",
    "PORT=13467 # change by another random port >10000\n",
    "docker run -it -p ${PORT}:8888 --shm-size=32gb --gpus '\"device='$DEVICE'\"' --user root --mount type=bind,source=${SOURCEPATH},target=${TARGETPATH} rbonazzola/learn_workshop:session_2\n",
    "```\n",
    "6. If the above worked, you should be inside the container. Launch Jupyter Lab or Jupyter Notebook from inside:\n",
    "```bash\n",
    "jupyter lab --ip \"0.0.0.0\" --allow-root --no-browser\n",
    "```\n",
    "\n",
    "7. Create an SSH tunnel (using MobaXterm on Windows, or the `ssh` option `\"-L ${PORT}:localhost:${PORT}\"` on Linux).\n",
    "8. Open your local web browser and insert `localhost:PORT` in the address bar, and copy the access token.\n",
    "9. Open this notebook, `LEARN_workshop/LEARN_workshop_session1.ipynb`. **Tip**: create a copy of this notebook (\"save as...\") if you plan to make changes to it. That will prevent future merge issues if you need to do pulls in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569ac6e-225b-436e-a801-b78d4c72ca35",
   "metadata": {},
   "source": [
    "For the SSH tunnel, this is a reference of the MobaXterm configuration that is needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0560c952-5d68-4fc0-a3ef-7e7967fb83ed",
   "metadata": {},
   "source": [
    "![](figures/local-port-forwarding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8d602",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b198d",
   "metadata": {},
   "source": [
    "## DGX hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6161b",
   "metadata": {},
   "source": [
    "- **GPU**: 40GB per GPU/320 GB per DGX A100 Node\n",
    "- **CPU**: 2-socket, 128 core AMD Rome 7742, 2.25 GHz (base), 3.4GHz (Max boost)\n",
    "- **System Memory**: 1 TB 3200 MHz DDR4.\n",
    "- **Storage:** \n",
    "    - **Default**: 15TB (4x3.84TB gen4 NVME).\n",
    "    - **Purchased with this machine**: 105 TB drive [PNY 3S-1050](https://www.scan.co.uk/3xs/configurator/3s-1050) AI-optimised storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216dae20",
   "metadata": {},
   "source": [
    "![](figures/DGX_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26925e9",
   "metadata": {},
   "source": [
    "## Multiple Instance GPU (MIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69417d94",
   "metadata": {},
   "source": [
    "(_from [Nvidia MIG user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/)_) \n",
    "\n",
    "The new Multi-Instance GPU (MIG) feature allows GPUs (starting with NVIDIA Ampere architecture) to be securely partitioned into up to seven separate GPU Instances for CUDA applications, providing multiple users with separate GPU resources for optimal GPU utilization. This feature is particularly beneficial for workloads that do not fully saturate the GPU's compute capacity and therefore users may want to run different workloads in parallel to maximize utilization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c42044",
   "metadata": {},
   "source": [
    "![](figures/DGX_MIG_partitioning_schemes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907c3ac",
   "metadata": {},
   "source": [
    "Currently, all the GPUs are partitioned into seven 5GB chunks (MIG devices), except GPU 6 which is partitioned into two 20GB MIG devices. Partitioning requires `sudo` so the admins (Ale and Kattia) have to be contacted in order to change this configuration.\n",
    "\n",
    "Examine the output of `nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222db56b",
   "metadata": {},
   "source": [
    "## Using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120fbac",
   "metadata": {},
   "source": [
    "Let's examine the environment. Run this from the command line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e56c59",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m torch.utils.collect_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686586fa",
   "metadata": {},
   "source": [
    "#### Set up GPU device in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(\"Torch CUDA available?\", torch.cuda.is_available())\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ef3e0",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fc38b",
   "metadata": {},
   "source": [
    "### Half-precision floating point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d66db1",
   "metadata": {},
   "source": [
    "- Uses 16-bit representations for floating point number. Default is usually 32 bits.\n",
    "- Saves memory.\n",
    "- Speeds up computation.\n",
    "- Feature also available in Nvidia V100 GPUs (ARC4, Bede, JADE2)\n",
    "- _Not_ available on P100 or K80 GPUs (ARC3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a591e",
   "metadata": {},
   "source": [
    "![](figures/DGX_16_bit_precision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f5d05",
   "metadata": {},
   "source": [
    "![](.figures/DGX_16_bit_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d09e2",
   "metadata": {},
   "source": [
    "#### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b161642",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "A32 = torch.Tensor(N, N).cuda()\n",
    "B32 = torch.Tensor(N, N).cuda()\n",
    "A16 = torch.Tensor(N, N).cuda().type(torch.float16)\n",
    "B16 = torch.Tensor(N, N).cuda().type(torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360cd6c",
   "metadata": {},
   "source": [
    "Let's perform element-wise matrix multiplication ($\\mathcal{O}(n^2)$) to compare the execution times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c26bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A16 * B16\n",
    "%timeit A32 * B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a85efc-c8fc-4e0a-8aa9-f4ef8e0017fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = A16 * B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b708f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A16 * B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f49632",
   "metadata": {},
   "outputs": [],
   "source": [
    "A16 = torch.Tensor(N, N).cuda().type(torch.bfloat16)\n",
    "B16 = torch.Tensor(N, N).cuda().type(torch.bfloat16)\n",
    "\n",
    "%timeit A16 * B16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8b920",
   "metadata": {},
   "source": [
    "Now, some standard matrix products ($\\mathcal{O}(n^3)$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da41051",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit torch.mm(A16, B16)\n",
    "# %timeit torch.mm(A32, B32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172680e8",
   "metadata": {},
   "source": [
    "### MNIST digit recognition (plain PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ab70d",
   "metadata": {},
   "source": [
    "Let's train a simple CNN MNIST classifier using plain PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "mnist_trainset, mnist_valset = torch.utils.data.random_split(mnist_trainset, [int(0.8 * len(mnist_trainset)), int(0.2 * len(mnist_trainset))])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=256, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_valset, batch_size=16, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier().cuda()\n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb2ff7-8c78-46ef-b141-edca2abc9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_EPOCHS = 10\n",
    "# train_loss = list()\n",
    "# val_loss = list()\n",
    "# best_val_loss = 1\n",
    "# \n",
    "# for epoch in range(N_EPOCHS):\n",
    "#     print(epoch)\n",
    "#     total_train_loss = 0\n",
    "#     total_val_loss = 0\n",
    "# \n",
    "#     model.train()\n",
    "#     # training\n",
    "#     for itr, (image, label) in enumerate(train_dataloader):\n",
    "#         image = image.to(device)\n",
    "#         label = label.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         # embed()\n",
    "# \n",
    "#         pred = model(image)\n",
    "# \n",
    "#         loss = ce_loss(pred, label)\n",
    "#         total_train_loss += loss.item()\n",
    "# \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# \n",
    "#     total_train_loss = total_train_loss / (itr + 1)\n",
    "#     train_loss.append(total_train_loss)\n",
    "#     \n",
    "#     # validation\n",
    "#     model.eval()\n",
    "#     total = 0\n",
    "#     for itr, (image, label) in enumerate(val_dataloader):\n",
    "#         \n",
    "#         image = image.to(device)\n",
    "#         label = label.to(device)\n",
    "#         pred = model(image)\n",
    "#  \n",
    "#         loss = ce_loss(pred, label)\n",
    "#         total_val_loss += loss.item()\n",
    "#  \n",
    "#         pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "#         for i, p in enumerate(pred):\n",
    "#             if label[i] == torch.max(p.data, 0)[1]:\n",
    "#                 total = total + 1\n",
    "#  \n",
    "#     accuracy = total / len(mnist_valset)\n",
    "#  \n",
    "#     total_val_loss = total_val_loss / (itr + 1)\n",
    "#     val_loss.append(total_val_loss)\n",
    "#  \n",
    "#     timestamp = time.strftime(\"%H:%M:%S\") \n",
    "#     print('\\n{} - Epoch: {}/{}, Train Loss: {:.8f}, Val Loss: {:.8f}, Val Accuracy: {:.8f}'.format(timestamp, epoch + 1, N_EPOCHS, total_train_loss, total_val_loss, accuracy))\n",
    "#  \n",
    "#     if total_val_loss < best_val_loss:\n",
    "#         best_val_loss = total_val_loss\n",
    "#         print(\"Saving the model state dictionary for Epoch: {} with Validation loss: {:.8f}\".format(epoch + 1, total_val_loss))\n",
    "#         torch.save(model.state_dict(), \"checkpoints/model.dth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a98b06",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a32069",
   "metadata": {},
   "source": [
    "### PyTorch Lightning (PTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbea83",
   "metadata": {},
   "source": [
    "- Library built on top of PyTorch.\n",
    "- Gets rid of boilerplate code.\n",
    "- **Allows to access hardware capabilities more easily.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as ptl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff611b28",
   "metadata": {},
   "source": [
    "It's built around three key abstractions:\n",
    "- `ptl.Module`: model itself plus specifications on what to do at each stage (training/validation/testing/inference)\n",
    "- `ptl.DataModule`: data + how to partition the data\n",
    "- `ptl.Trainer`: object that is fed with the two previous and performs the training. Hardware details must be specified through this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_ptl_callbacks import *\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "    rich_model_summary,\n",
    "    progress_bar\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257449d7",
   "metadata": {},
   "source": [
    "Let's import the ptl.Module and ptl.DataModule from the file `MNIST_lightning.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53946d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNIST_lightning import CNN_Module, MNIST_DataModule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f59ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea40ff6-d023-4c07-a693-22553f1275da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac74d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "PRECISION = \"32\" # try 32, 64, \"bf16\"\n",
    "\n",
    "datamodule = MNIST_DataModule(batch_size=BATCH_SIZE, split_lengths=[48000, 12000])\n",
    "\n",
    "ptl_module = CNN_Module(\n",
    "    model=MNISTClassifier()\n",
    ")\n",
    "\n",
    "trainer = ptl.Trainer(\n",
    "  devices='auto',\n",
    "  precision=PRECISION,\n",
    "  callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a355b-71df-4d0a-9128-e02b5866a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0378bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(ptl_module, datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
